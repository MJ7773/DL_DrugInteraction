{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"rf_lr_nnet_automl.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","source":["#install tpot library (for automl)\n","!pip install tpot "],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Ss5IQ0c-YwB2","outputId":"6f24c423-e7ae-4b7c-93da-13262ea39f55"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting tpot\n","  Downloading TPOT-0.11.7-py3-none-any.whl (87 kB)\n","\u001b[K     |████████████████████████████████| 87 kB 3.0 MB/s \n","\u001b[?25hRequirement already satisfied: pandas>=0.24.2 in /usr/local/lib/python3.7/dist-packages (from tpot) (1.1.5)\n","Requirement already satisfied: joblib>=0.13.2 in /usr/local/lib/python3.7/dist-packages (from tpot) (1.1.0)\n","Collecting stopit>=1.1.1\n","  Downloading stopit-1.1.2.tar.gz (18 kB)\n","Collecting update-checker>=0.16\n","  Downloading update_checker-0.18.0-py3-none-any.whl (7.0 kB)\n","Collecting deap>=1.2\n","  Downloading deap-1.3.1-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (160 kB)\n","\u001b[K     |████████████████████████████████| 160 kB 17.4 MB/s \n","\u001b[?25hRequirement already satisfied: numpy>=1.16.3 in /usr/local/lib/python3.7/dist-packages (from tpot) (1.19.5)\n","Requirement already satisfied: scipy>=1.3.1 in /usr/local/lib/python3.7/dist-packages (from tpot) (1.4.1)\n","Collecting xgboost>=1.1.0\n","  Downloading xgboost-1.5.1-py3-none-manylinux2014_x86_64.whl (173.5 MB)\n","\u001b[K     |████████████████████████████████| 173.5 MB 9.9 kB/s \n","\u001b[?25hRequirement already satisfied: tqdm>=4.36.1 in /usr/local/lib/python3.7/dist-packages (from tpot) (4.62.3)\n","Requirement already satisfied: scikit-learn>=0.22.0 in /usr/local/lib/python3.7/dist-packages (from tpot) (1.0.1)\n","Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.24.2->tpot) (2.8.2)\n","Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.24.2->tpot) (2018.9)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas>=0.24.2->tpot) (1.15.0)\n","Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.22.0->tpot) (3.0.0)\n","Requirement already satisfied: requests>=2.3.0 in /usr/local/lib/python3.7/dist-packages (from update-checker>=0.16->tpot) (2.23.0)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests>=2.3.0->update-checker>=0.16->tpot) (1.24.3)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.3.0->update-checker>=0.16->tpot) (2021.10.8)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2.3.0->update-checker>=0.16->tpot) (2.10)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests>=2.3.0->update-checker>=0.16->tpot) (3.0.4)\n","Building wheels for collected packages: stopit\n","  Building wheel for stopit (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for stopit: filename=stopit-1.1.2-py3-none-any.whl size=11952 sha256=21622bd18ed1375250ca1e0c52e307d5e8d92d1b2da924f22c3cbcd4d0b1dbd9\n","  Stored in directory: /root/.cache/pip/wheels/e2/d2/79/eaf81edb391e27c87f51b8ef901ecc85a5363dc96b8b8d71e3\n","Successfully built stopit\n","Installing collected packages: xgboost, update-checker, stopit, deap, tpot\n","  Attempting uninstall: xgboost\n","    Found existing installation: xgboost 0.90\n","    Uninstalling xgboost-0.90:\n","      Successfully uninstalled xgboost-0.90\n","Successfully installed deap-1.3.1 stopit-1.1.2 tpot-0.11.7 update-checker-0.18.0 xgboost-1.5.1\n"]}]},{"cell_type":"code","execution_count":null,"metadata":{"id":"V9HkZ7GkhBs2"},"outputs":[],"source":["#import necessary libraries\n","import pandas as pd \n","import numpy as np\n","\n","#import machine learning/deep learning libraries for training\n","from sklearn.model_selection import train_test_split\n","from sklearn.datasets import make_classification\n","from sklearn.ensemble import RandomForestClassifier\n","from sklearn.linear_model import LogisticRegression\n","from tpot import TPOTClassifier\n","from keras.models import Sequential\n","from keras.layers import Dense\n","\n","from numpy import mean\n","from numpy import std\n","\n","#import libraries for reporting metrics \n","import sklearn\n","from sklearn.metrics import precision_recall_curve\n","from sklearn.metrics import f1_score\n","from sklearn.metrics import accuracy_score\n","from sklearn.metrics import precision_score\n","from sklearn.metrics import recall_score\n","from sklearn.metrics import roc_auc_score\n","from sklearn.model_selection import GridSearchCV"]},{"cell_type":"code","source":["# data import and count number of positive, negative cases \n","all_data = pd.read_csv(\"all_list_enzyme.csv\", sep=\"\\t\")\n","pos_cnt = all_data[all_data['Class']==1].count()[1]\n","neg_cnt = all_data[all_data['Class']==0].count()[1]"],"metadata":{"id":"pYWEz6G-k3Rw"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["negative = all_data[all_data['Class']==0]"],"metadata":{"id":"nTbuix92Mojh"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#define neural network\n","model = Sequential()\n","model.add(Dense(12, input_dim=7, activation='relu'))\n","model.add(Dense(8, activation='relu'))\n","model.add(Dense(1, activation='sigmoid'))\n","model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"],"metadata":{"id":"heclMWwNNtj7"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["  #for hyperparameter tuning - logistic regression\n","  solvers = ['newton-cg', 'lbfgs', 'liblinear']\n","  penalty = ['l2']\n","  c_values = [100, 10, 1.0, 0.1, 0.01]\n","  grid2 = dict(solver=solvers,penalty=penalty,C=c_values)\n","\n","  #for hyperparameter tuning - random forest\n","  n_estimators = [10, 100, 1000]\n","  max_features = ['sqrt', 'log2']\n","  grid = dict(n_estimators=n_estimators,max_features=max_features)"],"metadata":{"id":"CjnHs_dW1iGZ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# lists for storing results \n","# rf means random forest\n","# lr means logistic regression\n","# model in this case means neural network model\n","# automl means AutoML implemented by tpot libraries \n","rf_auc_res =[]\n","rf_acc_res = []\n","rf_precision_res = []\n","rf_f1_res =[]\n","rf_recall_res = []\n","lr_auc_res =[]\n","lr_acc_res = []\n","lr_precision_res = []\n","lr_f1_res =[]\n","lr_recall_res = []\n","model_auc_res =[]\n","model_acc_res = []\n","model_precision_res = []\n","model_f1_res =[]\n","model_recall_res = []\n","automl_auc_res =[]\n","automl_acc_res = []\n","automl_precision_res = []\n","automl_f1_res =[]\n","automl_recall_res = []\n","\n","for i in range(5):\n","  # make data table for implementing model \n","  neg = all_data.query(\"Class ==0\").sample(70000)\n","  positive = all_data.query(\"Class ==1\").sample(70000)\n","  new_data = pd.concat([neg, positive])\n","  y = new_data['Class']\n","  X = new_data.drop(['Class','Drug1','Drug2'],1)\n","  X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1)\n","  \n","  #Random Forest model - model define, parameter tuning, training, predict, metric reporting\n","  rf = RandomForestClassifier()\n","  xtree = GridSearchCV(estimator=rf, param_grid=grid, n_jobs=-1, scoring='accuracy',error_score=0)\n","  xtree.fit(X_train, y_train)\n","  y_pred_xtree =xtree.predict(X_test)\n","  yhat_probs_xtree = xtree.predict_proba(X_test)\n","  rf_auc = roc_auc_score(y_test,yhat_probs_xtree[:, 1])\n","  rf_auc_res.append(rf_auc)\n","  rf_acc_res.append(accuracy_score(y_test, y_pred_xtree))\n","  rf_precision = precision_score(y_test, y_pred_xtree)\n","  rf_recall = recall_score(y_test, y_pred_xtree)\n","  rf_precision_res.append(rf_precision)\n","  rf_recall_res.append(rf_recall)\n","  rf_f1= f1_score(y_test, y_pred_xtree)\n","  rf_f1_res.append(rf_f1)\n","  \n","  #Logistic Regression model - model define, parameter tuning, training, predict, metric reporting\n","  lr = LogisticRegression()\n","  grid_search = GridSearchCV(estimator=lr, param_grid=grid2, n_jobs=-1,scoring='accuracy',error_score=0)\n","  logistic = grid_search.fit(X_train, y_train)\n","  y_pred_logistic =logistic.predict(X_test)\n","  yhat_probs_logistic = logistic.predict_proba(X_test)\n","  lr_auc = roc_auc_score(y_test,yhat_probs_logistic[:, 1])\n","  lr_auc_res.append(lr_auc)\n","  lr_acc_res.append(accuracy_score(y_test, y_pred_logistic))\n","  lr_precision = precision_score(y_test, y_pred_logistic)\n","  lr_recall = recall_score(y_test, y_pred_logistic)\n","  lr_precision_res.append(lr_precision)\n","  lr_recall_res.append(lr_recall)\n","  lr_f1= f1_score(y_test, y_pred_logistic)\n","  lr_f1_res.append(lr_f1)\n","  \n","  #Neural network model - model define, training, predict, metric reporting\n","  model.fit(X_train, y_train, epochs=40, batch_size=10, verbose=0)\n","  yhat_probs = model.predict(X_test, verbose=0)\n","  yhat_classes = (model.predict(X_test) > 0.5).astype(\"int32\")\n","  yhat_probs = yhat_probs[:, 0]\n","  yhat_classes = yhat_classes[:, 0]\n","  accuracy = accuracy_score(y_test, yhat_classes)\n","  precision = precision_score(y_test, yhat_classes)\n","  recall = recall_score(y_test, yhat_classes)\n","  f1 = f1_score(y_test, yhat_classes)\n","  auc = roc_auc_score(y_test, yhat_probs)\n","  model_auc_res.append(auc)\n","  model_acc_res.append(accuracy)\n","  model_precision_res.append(precision)\n","  model_recall_res.append(recall)\n","  model_f1_res.append(f1)\n","\n","  #AutoML - model define, training, predict, metric reporting\n","  tpot = TPOTClassifier(generations=5, population_size=10,scoring='accuracy', verbosity=2)\n","  tpot.fit(X_train, y_train)\n","  y_pred_tpot =tpot.predict(X_test)\n","  yhat_probs_tpot = tpot.predict_proba(X_test)\n","  automl_auc = roc_auc_score(y_test,yhat_probs_tpot[:, 1])\n","  automl_auc_res.append(automl_auc)\n","  automl_acc_res.append(accuracy_score(y_test, y_pred_tpot))\n","  automl_precision = precision_score(y_test, y_pred_tpot)\n","  automl_recall = recall_score(y_test, y_pred_tpot)\n","  automl_precision_res.append(automl_precision)\n","  automl_recall_res.append(automl_recall)\n","  automl_f1= f1_score(y_test, y_pred_tpot)\n","  automl_f1_res.append(automl_f1) \n","\n","  #new candidates \n","  negative = all_data[all_data['Class']==0]\n","  df = pd.concat([negative, neg])\n","  df = df.reset_index(drop=True)\n","  df_diff = pd.concat([negative,neg]).drop_duplicates(keep=False)\n","  df_diff1 = df_diff.drop(['Class','Drug1','Drug2'],1)\n","  y_pred_tpot =tpot.predict(df_diff1)\n","  yhat_probs_tpot = tpot.predict_proba(X_test)\n","  df_diff.reset_index(drop=True, inplace=True)\n","  predictions = pd.DataFrame(y_pred_tpot)\n","  prediction_prob = pd.DataFrame(yhat_probs_tpot)\n","  df_res1 = pd.concat([df_diff[['Drug1', 'Drug2']],predictions , prediction_prob], axis=1)\n","  df_res1.to_csv(\"prediction_res.csv\",sep=\"\\t\", index=None, header=None)"],"metadata":{"id":"0Rl1SWwvK3to"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(rf_auc_res)\n","print(rf_acc_res)\n","print(rf_precision_res)\n","print(rf_f1_res)\n","print(rf_recall_res)\n","print(lr_auc_res)\n","print(lr_acc_res)\n","print(lr_precision_res)\n","print(lr_f1_res)\n","print(lr_recall_res)\n","print(model_auc_res)\n","print(model_acc_res)\n","print(model_precision_res)\n","print(model_f1_res)\n","print(model_recall_res)\n","print(automl_auc_res)\n","print(automl_acc_res)\n","print(automl_precision_res)\n","print(automl_f1_res)\n","print(automl_recall_res)"],"metadata":{"id":"mYUARsJPtVZW"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# average across five iteration \n","print(mean(rf_auc_res))\n","print(mean(rf_acc_res))\n","print(mean(rf_precision_res))\n","print(mean(rf_f1_res))\n","print(mean(rf_recall_res))\n","print(mean(lr_auc_res))\n","print(mean(lr_acc_res))\n","print(mean(lr_precision_res))\n","print(mean(lr_f1_res))\n","print(mean(lr_recall_res))\n","print(mean(model_auc_res))\n","print(mean(model_acc_res))\n","print(mean(model_precision_res))\n","print(mean(model_f1_res))\n","print(mean(model_recall_res))\n","print(mean(automl_auc_res))\n","print(mean(automl_acc_res))\n","print(mean(automl_precision_res))\n","print(mean(automl_f1_res))\n","print(mean(automl_recall_res))"],"metadata":{"id":"vBlcK_60ctYp"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[""],"metadata":{"id":"lMOg8ZQitWkV"},"execution_count":null,"outputs":[]}]}